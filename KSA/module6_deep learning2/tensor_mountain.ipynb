{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature Box(2,)\n",
      "s.shape= (?, 2)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Affinity\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "w1==== <tf.Variable 'target_network/layer1/w1:0' shape=(2, 10) dtype=float32_ref>\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "Episode 1 with Reward : 4071.6179022861716 at epsilon 0.9001999999999335 in steps 81635\n",
      "target parameters changed\n",
      "Episode 2 with Reward : 155.1321212123788 at epsilon 0.9001999999999335 in steps 838\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "Episode 3 with Reward : 124.47323782426064 at epsilon 0.9001999999999335 in steps 853\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "target parameters changed\n",
      "Episode 4 with Reward : 183.21620043971382 at epsilon 0.9001999999999335 in steps 3026\n",
      "target parameters changed\n",
      "Episode 5 with Reward : 79.36096702712686 at epsilon 0.9001999999999335 in steps 296\n",
      "Episode 6 with Reward : 60.89047218245138 at epsilon 0.9001999999999335 in steps 202\n",
      "target parameters changed\n",
      "Episode 7 with Reward : 79.74372064553752 at epsilon 0.9001999999999335 in steps 300\n",
      "Episode 8 with Reward : 86.27653150798459 at epsilon 0.9001999999999335 in steps 289\n",
      "target parameters changed\n",
      "Episode 9 with Reward : 63.34639540488063 at epsilon 0.9001999999999335 in steps 207\n",
      "target parameters changed\n",
      "Episode 10 with Reward : 183.78535220127634 at epsilon 0.9001999999999335 in steps 580\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-609dca38ecf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\gym\\envs\\classic_control\\mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcartrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keys_to_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, return_rgb_array)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mflip\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_mouse_cursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\pyglet\\gl\\win32.py\u001b[0m in \u001b[0;36mflip\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0m_gdi32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSwapBuffers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vsync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Deep Q-Network: Mountain a 적용한 DQN 예제\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, learning_rate, gamma, n_features, n_actions, epsilon,\n",
    "                 parameter_changing_pointer, memory_size):\n",
    "        self.learning_rate = learning_rate  #학습률\n",
    "        self.gamma = gamma            #할인율\n",
    "        self.n_features = n_features  #자동차의 위치(0)와 속도(1)\n",
    "        self.n_actions = n_actions    #왼쪽으로 밀기(0), 보류(1), 오른쪽으로 밀기(2) \n",
    "        self.epsilon = epsilon        #탐욕 정책 시 활용되는 탐욕의 초기 값       \n",
    "        self.batch_size = 100         #재생 메모리로부터 추출되는 표본의 크기\n",
    "        self.experience_counter = 0   #현재 재생 메모리에 저장된 표본의 수\n",
    "        self.experience_limit = memory_size  #재생 메모리의 최대 용량\n",
    "        self.replace_target_pointer = parameter_changing_pointer  #target network 갱신 기준 학습 단계\n",
    "        self.learning_counter = 0                                 #primary network의 학습 단계\n",
    "        self.memory = np.zeros([self.experience_limit,self.n_features*2+2])  #재생 메모리의 초기값  \n",
    "\n",
    "        self.build_networks() #primary network과 target network을 생성\n",
    "        p_params = tf.get_collection('primary_network_parameters')\n",
    "        t_params = tf.get_collection('target_network_parameters')\n",
    "        self.replacing_target_parameters = [tf.assign(t,p) for t,p in zip(t_params,p_params)]\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#========== DQN 모형의 기본 신경망 및 목표 신경망을 설정하는 단계 ============#\n",
    "\n",
    "    def build_networks(self):\n",
    "        hidden_units = 10\n",
    "#.....................................................................#\n",
    "        # Primary Network: 각 10개의 은닉노드를 갖는 2개의 은닉층 \n",
    "        self.s = tf.placeholder(tf.float32,[None,self.n_features])\n",
    "        print('s.shape=',self.s.shape)\n",
    "        self.qtarget = tf.placeholder(tf.float32,[None,self.n_actions])\n",
    "\n",
    "        with tf.variable_scope('primary_network'): #변수 볌위를 관리한다.\n",
    "            c = ['primary_network_parameters', \n",
    "\t\t\t\t\ttf.GraphKeys.GLOBAL_VARIABLES]\n",
    "            # first layer\n",
    "            with tf.variable_scope('layer1'):\n",
    "                w1 = tf.get_variable('w1', [self.n_features, hidden_units],\n",
    "\t\t\t                         initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32,collections=c)\n",
    "\n",
    "                b1 = tf.get_variable('b1', [1, hidden_units],\n",
    "\t\t\t                         initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32,collections=c)\n",
    "\n",
    "                l1 = tf.nn.relu(tf.matmul(self.s, w1) + b1)\n",
    "\n",
    "            # second layer\n",
    "            with tf.variable_scope('layer2'):\n",
    "                w2 = tf.get_variable('w2', [hidden_units, self.n_actions],\n",
    "\t\t\t                         initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32,collections=c)\n",
    "\n",
    "                b2 = tf.get_variable('b2', [1, self.n_actions],\n",
    "\t\t\t                         initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32,collections=c)\n",
    "\n",
    "                self.qeval = tf.matmul(l1, w2) + b2f\n",
    "\n",
    "        with tf.variable_scope('loss'):\n",
    "                self.loss = tf.reduce_mean(tf.squared_difference(\n",
    "\t\t\t\t\t\tself.qtarget, self.qeval))\n",
    "        with tf.variable_scope('optimiser'):\n",
    "                self.train = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "#.....................................................................#\n",
    "        # Target Network\n",
    "        self.st = tf.placeholder(tf.float32,[None,self.n_features])\n",
    "\n",
    "        with tf.variable_scope('target_network'):\n",
    "            c = ['target_network_parameters', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "            # first layer\n",
    "            with tf.variable_scope('layer1'):\n",
    "                w1 = tf.get_variable('w1', [self.n_features, hidden_units],\n",
    "\t\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32,collections=c)\n",
    "                print('w1====',w1)\n",
    "                b1 = tf.get_variable('b1', [1, hidden_units],\n",
    "\t\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32,collections=c)\n",
    "\n",
    "                l1 = tf.nn.relu(tf.matmul(self.st, w1) + b1)\n",
    "\n",
    "            # second layer\n",
    "            with tf.variable_scope('layer2'):\n",
    "                w2 = tf.get_variable('w2', [hidden_units, self.n_actions],\n",
    "\t\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32,collections=c)\n",
    "\n",
    "                b2 = tf.get_variable('b2', [1, self.n_actions],\n",
    "\t\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                     dtype=tf.float32,collections=c)\n",
    "\n",
    "                self.qt = tf.matmul(l1, w2) + b2\n",
    "\n",
    "#-----------------------------------------------\n",
    "#기본 신경망의 학습 결과를 목표 신경망에 대입하기 위한 세션을 구성한다\n",
    "    def target_params_replaced(self):\n",
    "        self.sess.run(self.replacing_target_parameters)\n",
    "\n",
    "    def store_experience(self,obs,a,r,obs_):\n",
    "        index = self.experience_counter % self.experience_limit\n",
    "        self.memory[index,:] = np.hstack((obs,[a,r],obs_))\n",
    "        self.experience_counter+=1\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "#재생 메모리에 저장된 과거 경험을 설정한 배치 크기만큼 랜덤으로 추출하여 학습 데이터 집합으로 설정한다.\n",
    "    def fit(self):\n",
    "        # sample batch memory from all memory\n",
    "        if self.experience_counter < self.experience_limit:\n",
    "            indices = np.random.choice(self.experience_counter, size=self.batch_size)\n",
    "        else:\n",
    "            indices = np.random.choice(self.experience_limit, size=self.batch_size)\n",
    "\n",
    "        batch = self.memory[indices,:]\n",
    "        qt,qeval = self.sess.run([self.qt,self.qeval],\n",
    "\tfeed_dict={self.st:batch[:,-self.n_features:],self.s:batch[:,:self.n_features]})\n",
    "\n",
    "        qtarget = qeval.copy()    \n",
    "        batch_indices = np.arange(self.batch_size, dtype=np.int32)\n",
    "        actions = self.memory[indices,self.n_features].astype(int)\n",
    "        rewards = self.memory[indices,self.n_features+1]\n",
    "        qtarget[batch_indices,actions] = rewards + self.gamma * np.max(qt,axis=1)\n",
    "\n",
    "        _ = self.sess.run(self.train,feed_dict = {self.s:batch[:,:self.n_features],\n",
    "\t\t\t\t\t\t\tself.qtarget:qtarget})\n",
    "        if self.epsilon < 0.9:\n",
    "            self.epsilon += 0.0002\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "#학습 시 기본 신경망의 가중치를 가져와 목표 신경망의 가중치를 갱신한다.\n",
    "        if self.learning_counter % self.replace_target_pointer == 0:\n",
    "            self.target_params_replaced()\n",
    "            print(\"target parameters changed\")\n",
    "        self.learning_counter += 1\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "#탐욕 정책을 통해 행동을 선택하는 함수를 정의한다.\n",
    "    def epsilon_greedy(self,obs):\n",
    "        #epsilon greedy implementation to choose action\n",
    "        if np.random.uniform(low=0,high=1) < self.epsilon:\n",
    "            return np.argmax(self.sess.run(self.qeval,\n",
    "\t\t\t\t\tfeed_dict={self.s:obs[np.newaxis,:]}))\n",
    "        else:\n",
    "            return np.random.choice(self.n_actions)\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "#DQN 객체를 생성해 에이전트를 학습시키고 결과를 도출하는 단계\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make('MountainCar-v0')\n",
    "    env = env.unwrapped\n",
    "    print('feature',env.observation_space)\n",
    "    dqn = DQN(learning_rate=0.001, gamma=0.9, n_features=env.observation_space.shape[0],\n",
    "              n_actions=env.action_space.n, epsilon=0.0, parameter_changing_pointer=500, \n",
    "\t memory_size=5000)\n",
    "\n",
    "    episodes = 10\n",
    "    total_steps = 0\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        steps = 0\t\t\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        while True:\n",
    "            env.render()\n",
    "            action = dqn.epsilon_greedy(obs)\n",
    "            obs_,reward,terminate,_ = env.step(action)\n",
    "            reward = abs(obs_[0]+0.5)\n",
    "            dqn.store_experience(obs,action,reward,obs_)\n",
    "            if total_steps > 1000:\n",
    "                dqn.fit()\n",
    "            episode_reward+=reward\n",
    "            if terminate:\n",
    "                break\n",
    "            obs = obs_\n",
    "            total_steps+=1\n",
    "            steps+=1\n",
    "        print(\"Episode {} with Reward : {} at epsilon {} in steps {}\".\n",
    "\t\t\tformat(episode+1,episode_reward,dqn.epsilon,steps))\n",
    "\n",
    "    while True:  \n",
    "        env.render()\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-687cbce6b1ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106, 251,  30,  18, 401, 183, 335, 324, 105, 298, 412, 121, 285,\n",
       "       229, 374, 133, 103, 444, 130, 454, 378, 371,  29, 352, 104,  61,\n",
       "        34, 199, 327, 381])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(500,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array((1,2)).reshape(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.arange(20).reshape(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [20], [2,10].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1658\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [20], [2,10].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-aa98f96dbefc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2453\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2454\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2455\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5331\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   5332\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5333\u001b[1;33m                   name=name)\n\u001b[0m\u001b[0;32m   5334\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5335\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    789\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3300\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1823\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [20], [2,10]."
     ]
    }
   ],
   "source": [
    "tf.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,  10,  20,  30, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(([1,2,3],[10,20,30],[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "mypython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
